# placement

## Atributo `placement` da Chave `deploy` no Docker Compose: Gerenciamento Avançado da Distribuição de Contêineres

Este documento oferece uma explicação detalhada e completa sobre o atributo `placement` dentro da chave `deploy` em arquivos Docker Compose, focado no contexto do Docker Swarm. O `placement` permite controlar precisamente onde os serviços (contêineres) de uma aplicação serão executados em um cluster Docker Swarm, garantindo que suas necessidades de recursos e topologia sejam atendidas.

### Sumário

- **Introdução**: Contextualização do `deploy.placement` no ecossistema Docker.
- **Conceitos Fundamentais**: Entendimento da importância e propósito do `placement` em um cluster Swarm.
- **Sintaxe Detalhada e Uso Prático**: Exploração de `constraints` e `preferences` com exemplos de código comentados.
- **Cenários de Restrição ou Não Aplicação**: Limitações e considerações para o uso do `placement`.
- **Componentes Chave Associados**: Relação com rótulos de nó (`node.labels`) e propriedades de nó.
- **Melhores Práticas e Padrões de Uso**: Recomendações para otimizar a implantação de serviços.
- **Exemplo Prático Completo**: Um cenário demonstrando o uso de `placement` para uma aplicação multicamadas.

---

### 1\. Introdução

No desenvolvimento e implantação de aplicações em ambientes de contêineres, especialmente em orquestradores como o Docker Swarm, a capacidade de controlar onde os contêineres individuais de um serviço são executados é crucial. O atributo `placement` dentro da seção `deploy` de um arquivo `docker-compose.yml` (especificação da versão 3.x e superior, destinada ao uso com `docker stack deploy` em modo Swarm) oferece essa capacidade. Ele permite definir regras e preferências que o orquestrador Docker Swarm utilizará para alocar tarefas (instâncias de contêiner) para os nós disponíveis no cluster.

---

### 2\. Conceitos Fundamentais

O `deploy.placement` é um sub-atributo da chave `deploy`, que por sua vez é um atributo de um serviço. A chave `deploy` é opcional e fornece especificações de implantação para gerenciar o comportamento dos contêineres em diferentes ambientes, sendo aplicável apenas quando o Compose é utilizado para implantar serviços em um cluster Docker Swarm (via `docker stack deploy`). Se a seção `deploy` não for implementada ou se o `docker-compose up` for usado (que opera em um único host), ela será ignorada.

O propósito principal do `placement` é garantir que um serviço seja executado nos nós mais adequados, considerando requisitos específicos como:

- **Hardware especializado**: Garantir que um serviço que exige GPUs seja executado apenas em nós com GPUs.
- **Localização geográfica/zona de disponibilidade**: Distribuir instâncias de serviço por diferentes zonas para alta disponibilidade.
- **Isolamento de carga de trabalho**: Separar serviços de produção de serviços de desenvolvimento ou teste.
- **Recursos específicos**: Assegurar que serviços intensivos em I/O rodem em nós com SSDs.
- **Função do nó**: Restringir serviços a nós "manager" ou "worker".

O `placement` alcança isso através de `constraints` (restrições) e `preferences` (preferências).

---

### 3\. Sintaxe Detalhada e Uso Prático

A sintaxe do `placement` é definida da seguinte forma no `docker-compose.yml`:

```yaml
version: '3.8'
services:
  meu_servico:
    image: minha_imagem:latest
    deploy:
      # ... outras configurações de deploy
      placement:
        constraints:
          # Lista de restrições
          - "node.role == worker"          # Apenas em nós com a função worker
          - "node.labels.app_tier == backend" # Apenas em nós com o label 'app_tier'='backend'
          - "node.labels.disktype != hdd"   # Exclui nós com o label 'disktype'='hdd'
          - "node.hostname != server-dev"   # Exclui um nó específico pelo hostname
        preferences:
          # Lista de preferências
          - spread: "node.labels.zone"      # Espalha tarefas por diferentes zonas
          - spread: "node.labels.rack"      # Em seguida, espalha por racks dentro das zonas

```

### 3.1. `constraints` (Restrições)

As `constraints` são regras **obrigatórias** que um nó deve satisfazer para que uma tarefa do serviço seja agendada nele. Se um nó não atender a todas as restrições especificadas, a tarefa *não* será executada nesse nó. Múltiplas restrições funcionam como uma operação lógica **AND**: todas devem ser verdadeiras.

**Sintaxe dos `constraints`:**

`"propriedade_do_nó operador valor"`

**Propriedades de nó embutidas:**

- `node.id`: ID do nó.
- `node.hostname`: Nome do host do nó.
- `node.role`: Função do nó (manager ou worker).
- `node.platform.os`: Sistema operacional do nó (ex: linux, windows).
- `node.platform.arch`: Arquitetura do nó (ex: amd64, arm64).
- `node.description.hostname`: Nome do host do nó (similar a `node.hostname`).
- `node.description.platform.architecture`: Arquitetura da plataforma do nó.
- `node.description.platform.os`: Sistema operacional da plataforma do nó.
- `node.engine.labels.<label_name>`: Rótulos definidos no daemon Docker do nó.

**Operadores suportados:**

- `==`: Igual a.
- `!=`: Diferente de.

**Exemplos práticos de `constraints`:**

```yaml
services:
  web:
    image: nginx
    deploy:
      placement:
        constraints:
          - "node.role == worker" # O serviço 'web' só pode rodar em nós com a função 'worker'.
          - "node.platform.os == linux" # O serviço 'web' só pode rodar em nós Linux.

  banco_de_dados:
    image: postgres
    deploy:
      placement:
        constraints:
          - "node.labels.ssd == true" # O banco de dados só pode rodar em nós rotulados com 'ssd=true'.
                                     # Isso pressupõe que você adicionou esse label ao nó:
                                     # docker node update --label-add ssd=true <node_id_ou_hostname>
          - "node.hostname != dev-server-01" # Evita que o banco de dados rode em um servidor de desenvolvimento específico.

  servico_gpu:
    image: minha_imagem_cuda
    deploy:
      placement:
        constraints:
          - "node.labels.has_gpu == true" # O serviço que usa GPU só rodará em nós com GPU.
                                         # docker node update --label-add has_gpu=true <node_id_ou_hostname>

```

### 3.2. `preferences` (Preferências)

As `preferences` são regras **soft** ou "melhores esforços" que o agendador do Docker Swarm tenta seguir para distribuir as tarefas do serviço, mas não são obrigatórias para a implantação. Atualmente, a única estratégia suportada é `spread`.

A estratégia `spread` tenta distribuir as tarefas uniformemente pelos valores de um rótulo de nó especificado. Isso é ideal para aumentar a resiliência, garantindo que as instâncias do serviço não estejam concentradas em um único ponto de falha (ex: um único rack, uma única zona de disponibilidade).

**Sintaxe das `preferences`:**

```yaml
- spread: "propriedade_do_nó"

```

**Exemplos práticos de `preferences`:**

```yaml
services:
  minha_api:
    image: minha_api:latest
    replicas: 5 # Assumindo 5 réplicas para distribuição
    deploy:
      placement:
        preferences:
          - spread: "node.labels.zone" # Tenta espalhar as 5 réplicas entre nós em diferentes zonas de disponibilidade (se os nós tiverem o label 'zone').
          - spread: "node.labels.rack" # Se houver múltiplas zonas, então tenta espalhar por racks dentro de cada zona.

  cache_service:
    image: redis
    replicas: 3
    deploy:
      placement:
        preferences:
          - spread: "node.hostname" # Tenta agendar cada réplica em um host diferente, se possível.

```

É possível combinar `constraints` e `preferences`. O agendador primeiro aplica as `constraints` para filtrar os nós elegíveis e, em seguida, usa as `preferences` para distribuir as tarefas entre esses nós filtrados.

---

### 4\. Cenários de Restrição ou Não Aplicação

- **Docker Compose Standalone (`docker-compose up`)**: O atributo `deploy` (incluindo `placement`) é **ignorado** quando você usa `docker compose up` ou `docker-compose up`. Ele só é efetivo ao implantar uma stack em um cluster Docker Swarm usando `docker stack deploy`. Isso ocorre porque `docker-compose up` gerencia contêineres em um único host Docker Engine, que não possui o conceito de orquestração de nós ou agendamento de swarm.
- **Ausência de Docker Swarm**: Para que o `placement` funcione, o ambiente Docker deve estar no modo Swarm (ou seja, você deve ter inicializado um swarm com `docker swarm init` ou ter juntado nós a um swarm existente).
- **Labels Inexistentes ou Incorretos**: Se você definir `constraints` ou `preferences` baseadas em rótulos de nó (`node.labels.meu_label`) e esses rótulos não existirem ou estiverem incorretos nos nós do seu swarm, as restrições podem não ser satisfeitas e os serviços podem não ser implantados ou serem agendados de forma indesejada.
- **Conflitos de Restrição**: Restrições muito rígidas ou conflitantes podem levar a um estado onde não há nós elegíveis para executar o serviço, resultando em falha na implantação. Por exemplo, `node.labels.os == linux` E `node.labels.os == windows` nunca será satisfeito.
- **Limitação da Estratégia `spread`**: A `preferences` atualmente suporta apenas a estratégia `spread`. Se você precisar de estratégias de agendamento mais complexas (como `binpack` ou agendamento por afinidade mais avançado), talvez precise de orquestradores mais sofisticados como Kubernetes.
- **Migração de Tarefas**: O Docker Swarm não move proativamente as tarefas se os rótulos de um nó mudarem após a implantação inicial. As restrições e preferências são avaliadas no momento do agendamento da tarefa.

---

### 5\. Componentes Chave Associados

O funcionamento do `placement` depende fundamentalmente dos **rótulos de nó (node labels)** e das **propriedades de nó** no Docker Swarm.

- **Rótulos de Nó (`node.labels.<label_name>`)**:
    - São pares chave-valor arbitrários que você pode aplicar aos nós do seu cluster Swarm.
    - São usados para marcar nós com características específicas (ex: `disktype=ssd`, `datacenter=dc1`, `gpu=nvidia`, `tier=frontend`).
    - Você os adiciona usando o comando `docker node update --label-add <key>=<value> <node_id_ou_hostname>`.
    - Permitem que você crie um "vocabulário" personalizado para descrever seus recursos de hardware e infraestrutura.
    
    <!-- end list -->
    
    ```bash
    # Exemplo: Adicionar um label a um nó
    docker node update --label-add disktype=ssd worker-node-1
    docker node update --label-add environment=production manager-node-1
    
    ```
    
- **Propriedades de Nó Embutidas**:
    - São informações intrínsecas e automaticamente detectadas sobre o nó pelo Docker Swarm.
    - Incluem `node.id`, `node.hostname`, `node.role`, `node.platform.os`, `node.platform.arch`, etc.
    - São úteis para restrições básicas e universais que não dependem de labels customizados.

A interação entre `placement`, rótulos de nó e propriedades de nó permite que os administradores de cluster e desenvolvedores definam políticas de agendamento sofisticadas que garantam o uso eficiente e confiável dos recursos do swarm.

---

### 6\. Melhores Práticas e Padrões de Uso

- **Rotule seus Nós de Forma Consistente**: Crie um esquema de rotulagem claro e consistente para todos os nós no seu cluster Swarm. Isso facilitará a definição de restrições e preferências.
- **Comece com Restrições Necessárias**: Primeiro, defina as `constraints` que são absolutamente essenciais para a funcionalidade do seu serviço (ex: requisitos de SO, presença de hardware específico).
- **Use Preferências para Resiliência e Desempenho**: Em seguida, adicione `preferences` para otimizar a distribuição de carga e a resiliência (ex: espalhar por zonas de disponibilidade, racks, hostnames).
- **Evite Restrições Excessivamente Rígidas**: Restrições muito específicas ou em grande número podem tornar o agendamento inflexível e levar a falhas de implantação se o número de nós elegíveis for muito baixo ou zero.
- **Teste Suas Configurações de `placement`**: Antes de implantar em produção, teste suas configurações de `placement` em um ambiente de staging para garantir que os serviços são agendados conforme o esperado e que não há conflitos.
- **Monitore o Agendamento**: Use `docker service ps <service_name>` e `docker node ls` para monitorar onde as tarefas estão sendo executadas e verificar se as políticas de `placement` estão sendo respeitadas.
- **Documente suas Políticas de `placement`**: Mantenha uma documentação clara sobre como e por que as restrições e preferências de `placement` são usadas em seus serviços.

---

### 7\. Exemplo Prático Completo

Imagine um cluster Docker Swarm com três nós, cada um com diferentes características:

- `node-manager-1`: Função `manager`, com rótulo `zone=us-east-1a`, `tier=control`.
- `node-worker-1`: Função `worker`, com rótulo `zone=us-east-1a`, `disktype=ssd`, `tier=application`.
- `node-worker-2`: Função `worker`, com rótulo `zone=us-east-1b`, `disktype=hdd`, `tier=application`.

Nosso objetivo é implantar uma aplicação web de três camadas (frontend, backend, database) com as seguintes políticas:

- **`frontend`**: Requer 3 réplicas, deve rodar em nós `worker`, e ser espalhado por zonas para alta disponibilidade.
- **`backend`**: Requer 2 réplicas, deve rodar em nós `worker` e preferencialmente em nós com `disktype=ssd` para melhor desempenho.
- **`database`**: Requer 1 réplica, deve rodar *apenas* em nós com `disktype=ssd` e na `zone=us-east-1a` para consistência e desempenho.

**`docker-compose.yml`:**

```yaml
version: '3.8'

services:
  frontend:
    image: meuapp/frontend:latest
    ports:
      - "80:80"
    replicas: 3
    deploy:
      mode: replicated
      placement:
        constraints:
          - "node.role == worker" # Restrição: Apenas em nós worker
        preferences:
          - spread: "node.labels.zone" # Preferência: Espalhar entre as zonas

  backend:
    image: meuapp/backend:latest
    ports:
      - "8080:8080"
    replicas: 2
    deploy:
      mode: replicated
      placement:
        constraints:
          - "node.role == worker" # Restrição: Apenas em nós worker
        preferences:
          - spread: "node.labels.disktype" # Preferência: Espalhar entre os tipos de disco
          - spread: "node.labels.tier" # Outra preferência: Espalhar por tier

  database:
    image: postgres:13
    volumes:
      - db_data:/var/lib/postgresql/data
    environment:
      POSTGRES_DB: mydatabase
      POSTGRES_USER: user
      POSTGRES_PASSWORD: password
    replicas: 1
    deploy:
      mode: replicated
      placement:
        constraints:
          - "node.labels.disktype == ssd" # Restrição forte: Apenas em nós com SSD
          - "node.labels.zone == us-east-1a" # Restrição forte: Apenas na zona us-east-1a
          - "node.role == worker" # Restrição: Apenas em nós worker (embora as outras já impliquem isso)

volumes:
  db_data:

```

**Para implantar esta stack no Swarm:**

1. **Inicialize o Swarm (se ainda não o fez):**
    
    ```bash
    docker swarm init --advertise-addr <IP_DO_MANAGER>
    
    ```
    
2. **Adicione rótulos aos seus nós:**
    
    ```bash
    # No node-manager-1:
    docker node update --label-add zone=us-east-1a --label-add tier=control node-manager-1
    
    # No node-worker-1:
    docker node update --label-add zone=us-east-1a --label-add disktype=ssd --label-add tier=application node-worker-1
    
    # No node-worker-2:
    docker node update --label-add zone=us-east-1b --label-add disktype=hdd --label-add tier=application node-worker-2
    
    ```
    
3. **Implante a stack:**
    
    ```bash
    docker stack deploy -c docker-compose.yml minha_aplicacao
    
    ```
    

**Resultado Esperado:**

- O **`frontend`** (3 réplicas) será distribuído entre `node-worker-1` (zone `us-east-1a`) e `node-worker-2` (zone `us-east-1b`), buscando espalhar as tarefas entre as zonas.
- O **`backend`** (2 réplicas) será agendado em `node-worker-1` e `node-worker-2`, com preferência por nós com SSDs. O Swarm tentará equilibrar a carga, mas priorizará nós com `disktype=ssd`.
- O **`database`** (1 réplica) será agendado **apenas** no `node-worker-1`, pois é o único nó que satisfaz as duas restrições: `disktype=ssd` E `zone=us-east-1a` E `node.role == worker`.

---

### Sugestões para Aprofundamento:

- **Documentação Oficial do Docker sobre Deploy**: Para a fonte mais autoritativa e atualizada sobre a especificação `deploy`: [Compose Deploy Specification - Docker Docs](https://docs.docker.com/reference/compose-file/deploy/)
- **Guia de Placement no Docker Swarm**: Para uma compreensão mais aprofundada de como o Swarm lida com o agendamento e a colocação de serviços: [Placement in Swarm - KodeKloud Notes](https://notes.kodekloud.com/docs/Docker-Certified-Associate-Exam-Course/Docker-Swarm/Placement-in-Swarm)
- **Gerenciamento de Nós e Rótulos**: Entender como gerenciar e inspecionar nós e seus rótulos é fundamental: [Docker node update CLI](https://docs.docker.com/engine/reference/commandline/node_update/)

Espero que esta explicação detalhada e abrangente ajude Gedê a entender o atributo `placement` no Docker Compose\!