# cpus

Claro, Gedê\! A.R.I.A está aqui para te ajudar a entender o atributo `cpus` no Docker Compose. Vamos mergulhar fundo nesse tema, especialmente porque você, como desenvolvedor Backend Java em transição para Go, se preocupa com o desempenho dos seus serviços.

---

## Gerenciando o Uso de CPU com o Atributo `cpus` no Docker Compose

### Introdução

No universo do Docker e, mais especificamente, do **Docker Compose**, o controle de recursos é fundamental para garantir que suas aplicações rodem de forma eficiente e estável, sem monopolizar os recursos do host ou de outros serviços. O atributo **`cpus`** da chave `services` surge como uma ferramenta poderosa nesse cenário, permitindo que você defina limites para o uso de CPU por cada serviço em seu arquivo `docker-compose.yml`. Entender e aplicar corretamente esse atributo é crucial para otimizar o desempenho, evitar gargalos e garantir uma alocação justa de recursos em ambientes de desenvolvimento e produção.

### Sumário

Nesta explicação detalhada, abordaremos os seguintes pontos:

- **Conceitos Fundamentais:** Entender o que é o `cpus`, sua importância e como ele se relaciona com o gerenciamento de recursos no Docker.
- **Sintaxe Detalhada e Uso Prático:** Como declarar e utilizar o atributo `cpus` em seu arquivo `docker-compose.yml`, com exemplos claros e comentados.
- **Cenários de Restrição ou Não Aplicação:** Quando o `cpus` pode não ser a melhor escolha ou ter limitações.
- **Componentes Chave Associados:** Outros atributos relacionados ao controle de CPU, como `cpu_shares`, `cpu_quota`, `cpu_period` e `cpuset`, e como eles interagem.
- **Melhores Práticas e Padrões de Uso:** Recomendações para utilizar o `cpus` de forma eficaz.
- **Exemplo Prático Completo:** Um cenário de ponta a ponta mostrando a aplicação do `cpus` em um projeto.

---

### Conceitos Fundamentais

O atributo **`cpus`** no Docker Compose (parte da especificação de recursos do `services`) permite que você **limite a quantidade de ciclos de CPU** que um determinado serviço pode consumir. Ele é expresso como um **número de ponto flutuante positivo**, representando a quantidade de CPUs ou núcleos disponíveis para o serviço.

**Por que isso é importante?**

Imagine que você tem um servidor com 4 núcleos de CPU e está executando vários serviços Docker Compose, como um banco de dados, um backend Java (ou Go, no seu caso, Gedê\!) e um frontend. Se um desses serviços (digamos, seu backend) entrar em um loop infinito ou tiver uma carga de processamento inesperadamente alta, ele poderia **monopolizar todos os núcleos da CPU**, deixando os outros serviços sem recursos e, consequentemente, tornando a aplicação inteira lenta ou até mesmo indisponível.

O `cpus` atua como um **freio de segurança**, garantindo que nenhum serviço exceda o limite de CPU que você especificou, mesmo sob alta demanda. Isso proporciona:

- **Estabilidade:** Evita que um serviço "mate" outros serviços ao consumir todos os recursos de CPU.
- **Performance Consistente:** Ajuda a garantir que cada serviço tenha uma fatia justa dos recursos, mantendo um nível de desempenho previsível.
- **Gerenciamento de Custos (em nuvem):** Em ambientes de nuvem, onde o uso de CPU é muitas vezes cobrado, limitar o `cpus` pode ajudar a controlar gastos.
- **Melhor Utilização de Recursos:** Permite que você distribua os recursos de CPU de forma mais inteligente entre seus contêineres.

É importante notar que `cpus` é uma abstração mais **simples e de alto nível** em comparação com outros atributos de controle de CPU, como `cpu_shares` e `cpu_quota`/`cpu_period`. Enquanto os últimos oferecem um controle mais granular e são baseados em "fatias" de tempo de CPU, `cpus` tenta simular o número de núcleos dedicados para um serviço. Por exemplo, `cpus: 0.5` significa que o serviço tentará usar o equivalente a metade de um núcleo de CPU, enquanto `cpus: 2` significa que ele pode usar o equivalente a dois núcleos inteiros.

---

### Sintaxe Detalhada e Uso Prático

O atributo `cpus` é definido sob a chave `deploy.resources.limits` ou `deploy.resources.reservations` de um serviço no arquivo `docker-compose.yml`.

- **`limits`**: Define o **limite máximo** de CPU que um serviço pode consumir. O escalonador do Docker garantirá que o serviço não ultrapasse essa alocação, mesmo que haja recursos de CPU ociosos disponíveis no host.
- **`reservations`**: Define a **quantidade mínima** de CPU que um serviço *tentará* reservar. O Docker tentará garantir que essa quantidade de CPU esteja disponível para o serviço, mesmo sob contenção de recursos. Se não houver recursos suficientes para satisfazer a reserva, o serviço pode não ser agendado ou pode ter seu desempenho degradado.

A sintaxe é bastante direta:

```yaml
version: '3.8' # Recomenda-se a versão 3.8 ou superior para deploy.resources

services:
  meu_backend:
    image: minha-imagem-backend:latest
    ports:
      - "8080:8080"
    deploy:
      resources:
        limits:
          cpus: '0.5' # Limita o serviço a usar no máximo 50% de um núcleo de CPU
        reservations:
          cpus: '0.2' # Tenta reservar 20% de um núcleo de CPU para este serviço

  meu_banco_dados:
    image: postgres:13
    volumes:
      - db_data:/var/lib/postgresql/data
    deploy:
      resources:
        limits:
          cpus: '1.0' # Limita o serviço a usar no máximo 1 núcleo de CPU
        reservations:
          cpus: '0.5' # Tenta reservar 50% de um núcleo de CPU para este serviço

  meu_frontend:
    image: minha-imagem-frontend:latest
    ports:
      - "3000:3000"
    deploy:
      resources:
        limits:
          cpus: '0.25' # Limita o serviço a usar no máximo 25% de um núcleo de CPU

```

**Explicação dos Valores:**

- **`cpus: '0.5'`**: Indica que o serviço `meu_backend` pode usar o equivalente a **metade de um núcleo de CPU**. Se o host tiver múltiplos núcleos, o Docker distribuirá o tempo de CPU de forma que este serviço não consuma mais do que 0.5 de um núcleo.
- **`cpus: '1.0'`**: Permite que o serviço `meu_banco_dados` use o equivalente a **um núcleo de CPU inteiro**.
- **`cpus: '2.0'`**: Se você tivesse um serviço com alta demanda, poderia alocar o equivalente a **dois núcleos de CPU**.

**Observações Importantes:**

- O valor deve ser uma **string** (por exemplo, `'0.5'`) e não um número float diretamente (`0.5`), embora em algumas versões do Docker Compose ambos possam funcionar, a string é a forma mais segura e recomendada pela documentação para garantir compatibilidade e evitar problemas de análise de YAML.
- O Docker, por baixo dos panos, converte esses valores `cpus` em combinações de `cpu_quota` e `cpu_period`, que veremos mais adiante.
- Para que `deploy.resources` funcione, o Docker Engine deve estar em **modo Swarm**. Mesmo que você não esteja usando um cluster Swarm completo, o comando `docker stack deploy` exige que o Swarm esteja inicializado (`docker swarm init`). Para uso com `docker compose up`, esses limites podem não ser impostos da mesma forma rigorosa pelo Docker Compose standalone (dependendo da versão e configuração), mas são crucialmente importantes para o comportamento do serviço em um cluster Swarm. No entanto, o `docker-compose` moderno (V2) agora também impõe esses limites localmente sem precisar de Swarm. É sempre bom verificar a documentação específica da sua versão do Docker Compose.

---

### Cenários de Restrição ou Não Aplicação

Embora o atributo `cpus` seja muito útil, existem situações em que ele pode não ser a melhor solução ou ter limitações:

1. **Ambientes de Desenvolvimento Leves:** Para aplicações simples em desenvolvimento local onde o controle de recursos não é crítico, adicionar limites de CPU pode ser um excesso de configuração e potencialmente mascarar problemas de desempenho que apareceriam em ambientes de produção. Nesses casos, a simplicidade pode ser preferida.
2. **Over-provisionamento Excessivo:** Se você limitar severamente a CPU de um serviço que tem picos de alta demanda (mas com média baixa), você pode estar criando um gargalo artificial. O serviço pode ser estrangulado e ter seu desempenho degradado, mesmo que o host tenha CPU ociosa disponível.
3. **Containers de Curta Duração/Batch:** Para tarefas muito rápidas e que consomem CPU por um curto período (por exemplo, um script de processamento de dados que roda e termina), a sobrecarga de gerenciar o limite de CPU pode ser mínima, e o benefício de limitá-lo também. Nesses casos, permitir que o contêiner use o que precisa e depois libere pode ser mais eficiente.
4. **Hardware Antigo ou Limitado:** Em sistemas com poucos núcleos de CPU (ex: um único núcleo), alocar frações de CPU pode ter um impacto mais perceptível no desempenho dos serviços. Nesses casos, o controle de CPU é ainda mais crítico, mas a granularidade pode ser limitada.
5. **Quando `cpu_shares` é Mais Adequado:** Se você quer que os serviços *compartilhem* a CPU de forma ponderada (ou seja, quando há contenção, serviços com mais `cpu_shares` recebem mais tempo de CPU, mas se houver CPU ociosa, todos podem usar o máximo), `cpu_shares` pode ser uma opção melhor que `cpus` para alocação *relativa* de recursos. `cpus` impõe um limite *absoluto*.
6. **Compatibilidade do Docker Engine:** Versões muito antigas do Docker Engine ou do Docker Compose podem não suportar a sintaxe `deploy.resources.limits.cpus`. Sempre verifique a documentação da sua versão.

---

### Componentes Chave Associados

O atributo `cpus` é uma forma simplificada de gerenciar o uso de CPU, mas o Docker oferece mecanismos mais granulares por baixo dos panos, que são: `cpu_shares`, `cpu_quota` e `cpu_period`. O `cpus` geralmente é traduzido pelo Docker para uma combinação de `cpu_quota` e `cpu_period`.

Vamos entender esses componentes, que você pode usar diretamente se precisar de um controle mais fino:

### 1\. `cpu_shares`

- **Propósito:** Define a proporção relativa de tempo de CPU que um contêiner recebe quando há contenção de recursos de CPU. Não é um limite absoluto, mas uma "dica" para o escalonador.
- **Sintaxe:** `cpu_shares: <valor_inteiro>` (padrão é 1024)
- **Comportamento:** Se você tiver dois serviços, um com `cpu_shares: 1024` e outro com `cpu_shares: 512`, o primeiro receberá o dobro de tempo de CPU que o segundo *apenas quando o sistema estiver sob alta carga de CPU*. Se houver CPU disponível, ambos podem usar o máximo que puderem.
- **Exemplo:**
    
    ```yaml
    services:
      servico_alto_prioridade:
        image: meu-app
        cpus: '0.75' # Usando cpus para limite absoluto
        cpu_shares: 2048 # E cpu_shares para prioridade relativa se houver contenção
      servico_baixa_prioridade:
        image: outro-app
        cpus: '0.25'
        cpu_shares: 512
    
    ```
    

### 2\. `cpu_period` e `cpu_quota`

Esses dois atributos trabalham em conjunto para definir um **limite absoluto** no tempo de CPU que um contêiner pode usar dentro de um determinado período.

- **`cpu_period`**: Define a duração de um período de agendamento de CPU em **microssegundos**. O valor padrão é 100.000 microssegundos (100 ms).
- **`cpu_quota`**: Define a quantidade máxima de tempo de CPU que um contêiner pode usar dentro de cada `cpu_period`, também em **microssegundos**.
- **Relação com `cpus`**: O valor de `cpus` é internamente convertido para `cpu_quota` e `cpu_period`.
    - `cpu_quota = cpus * cpu_period`
    - Por exemplo, `cpus: 0.5` com um `cpu_period` padrão de 100.000 microssegundos resulta em `cpu_quota = 0.5 * 100.000 = 50.000` microssegundos. Isso significa que o contêiner pode usar 50.000 microssegundos de CPU a cada 100.000 microssegundos.
- **Sintaxe:**
    
    ```yaml
    services:
      servico_preciso:
        image: app-cpu-bound
        deploy:
          resources:
            limits:
              cpu_period: 100000 # Padrão, em microssegundos
              cpu_quota: 50000  # 50% de um núcleo (50.000 / 100.000)
    
    ```
    
    Ou de forma simplificada, usando `cpus`:
    
    ```yaml
    services:
      servico_preciso:
        image: app-cpu-bound
        deploy:
          resources:
            limits:
              cpus: '0.5' # Equivalente a cpu_period: 100000 e cpu_quota: 50000
    
    ```
    
    **Quando usar `cpu_period` e `cpu_quota` diretamente?**
    Quando você precisa de um controle mais preciso sobre a "janela de tempo" na qual o limite de CPU é aplicado, o que pode ser útil para cargas de trabalho muito sensíveis ao tempo ou para otimização em cenários específicos. Para a maioria dos casos, o `cpus` é suficiente e mais fácil de entender.
    

### 3\. `cpuset`

- **Propósito:** Fixa um contêiner em um conjunto específico de núcleos de CPU disponíveis no host. Isso pode ser útil para aplicações que se beneficiam de cache de CPU dedicado ou para evitar a sobrecarga de migração entre núcleos.
- **Sintaxe:** `cpuset: "0,1"` ou `cpuset: "0-2"`
- **Comportamento:** `cpuset: "0,1"` significa que o contêiner só pode rodar nos núcleos 0 e 1 do host. `cpuset: "0-2"` significa que ele pode rodar nos núcleos 0, 1 e 2.
- **Exemplo:**
    
    ```yaml
    services:
      servico_critico:
        image: outro-app
        deploy:
          resources:
            limits:
              cpus: '1.0'
            cpuset: "0" # Fixa o contêiner no núcleo 0
    
    ```
    
    **Cuidado:** Usar `cpuset` pode levar à subutilização de CPU se os núcleos especificados estiverem ociosos e outros núcleos estiverem ocupados. Geralmente, é mais utilizado em cenários de alta performance ou com requisitos muito específicos de isolamento.
    

---

### Melhores Práticas e Padrões de Uso

Ao utilizar o atributo `cpus` (e outros limites de CPU), considere as seguintes melhores práticas:

1. **Comece com Calma:** Não super-otimize desde o início. Comece com limites razoáveis ou até sem limites em ambientes de desenvolvimento e, em seguida, monitore o uso de CPU. Ferramentas como `docker stats` ou ferramentas de monitoramento mais avançadas são seus melhores amigos aqui.
2. **Monitore, Monitore, Monitore:** É impossível definir os limites ideais sem entender como suas aplicações se comportam sob carga. Observe os picos e as médias de uso de CPU. Se seu serviço está frequentemente atingindo o limite de `cpus` e a performance está sofrendo, talvez seja necessário aumentar o limite ou otimizar o código da aplicação.
3. **Entenda sua Aplicação:**
    - **CPU-Bound vs. I/O-Bound:** Se sua aplicação é predominantemente CPU-bound (realiza muitos cálculos, por exemplo, como um serviço de processamento de imagens), ela se beneficiará mais de mais CPU. Se for I/O-bound (passa a maior parte do tempo esperando por operações de disco ou rede, como um serviço de API que consulta um banco de dados), o impacto de mais CPU pode ser menor.
    - **Número de Threads:** Uma aplicação que utiliza muitas threads pode se beneficiar de mais núcleos virtuais (ou seja, um valor `cpus` mais alto), pois ela pode paralelizar o trabalho.
4. **Teste em Ambiente Realista:** As configurações de recursos devem ser testadas em um ambiente que se assemelhe o máximo possível ao ambiente de produção.
5. **Use `limits` e `reservations` com Propósito:**
    - Use **`limits`** para **proteger o host** e outros serviços de um serviço descontrolado. É uma forma de contenção.
    - Use **`reservations`** para **garantir um desempenho mínimo** para serviços críticos, assegurando que eles sempre tenham uma fatia de CPU disponível, mesmo sob contenção.
6. **Documente suas Configurações:** Registre os motivos pelos quais você definiu certos limites de CPU. Isso ajuda na manutenção e na resolução de problemas futuros.
7. **Considere a Contenção de Recursos:** Lembre-se que o Docker está agendando contêineres no mesmo host. Se a soma dos `reservations` de todos os seus serviços exceder o número de CPUs disponíveis no host, você terá contenção, e o agendador do Docker tentará compensar, o que pode levar a degradação de desempenho.

---

### Exemplo Prático Completo

Vamos criar um cenário simples com um backend (Java/Go, Gedê, você decide\!) e um serviço de monitoramento que usará o atributo `cpus`.

Nosso objetivo será:

- Limitar o backend a no máximo 1 núcleo de CPU, mas garantir que ele tenha acesso a pelo menos 0.5 de um núcleo.
- Limitar o serviço de monitoramento a 0.25 de um núcleo.

**Estrutura de Arquivos:**

```
.
├── docker-compose.yml
├── backend/
│   └── Dockerfile
│   └── app.jar # (ou main.go para Go)
└── monitoring/
    └── Dockerfile
    └── monitor.py

```

**`backend/Dockerfile` (Exemplo para Java - adapte para Go se preferir):**

```
FROM openjdk:17-jdk-slim
WORKDIR /app
COPY app.jar .
CMD ["java", "-jar", "app.jar"]

```

**`backend/app.jar` (Um app Java simples que consome CPU):**
(Você precisaria compilar um Jar que faça algum cálculo pesado para ver o limite em ação, por exemplo, um loop infinito ou cálculo de Fibonacci recursivo).

```java
// Exemplo simples para fins de demonstração (salve como CpuIntensiveApp.java e compile)
public class CpuIntensiveApp {
    public static void main(String[] args) {
        System.out.println("Backend iniciado, consumindo CPU...");
        long count = 0;
        while (true) {
            count++;
            if (count % 1_000_000_000L == 0) {
                System.out.println("Processando... " + count);
            }
            // Pequena pausa para não travar completamente (opcional, remova para alto consumo)
            // try { Thread.sleep(1); } catch (InterruptedException e) {}
        }
    }
}

```

*Compilar com `javac CpuIntensiveApp.java` e depois `jar cfe app.jar CpuIntensiveApp CpuIntensiveApp.class`*

**`monitoring/Dockerfile`:**

```
FROM python:3.9-slim-buster
WORKDIR /app
COPY monitor.py .
CMD ["python", "monitor.py"]

```

**`monitoring/monitor.py` (Um script Python que simula um serviço de monitoramento leve):**

```python
import time
import os

print("Serviço de Monitoramento iniciado.")
hostname = os.uname()[1] # Obter hostname do contêiner

while True:
    print(f"[{hostname}] Monitorando... (CPU limit 0.25)", flush=True)
    time.sleep(5) # Simula algum trabalho leve a cada 5 segundos

```

**`docker-compose.yml`:**

```yaml
version: '3.8'

services:
  backend-app:
    build: ./backend
    ports:
      - "8080:8080"
    deploy:
      resources:
        limits:
          cpus: '1.0' # Limita a no máximo 1 núcleo de CPU
        reservations:
          cpus: '0.5' # Garante pelo menos 0.5 de um núcleo
    healthcheck:
      test: ["CMD", "curl", "-f", "<http://localhost:8080>"]
      interval: 10s
      timeout: 5s
      retries: 3

  monitoring-service:
    build: ./monitoring
    deploy:
      resources:
        limits:
          cpus: '0.25' # Limita a no máximo 0.25 de um núcleo de CPU

```

**Como rodar e observar:**

1. **Crie os arquivos** e a estrutura de pastas conforme acima.
2. **Navegue até a pasta raiz** do projeto no terminal.
3. **Compile a imagem do backend (se for Java):**`cd backendjavac CpuIntensiveApp.javajar cfe app.jar CpuIntensiveApp CpuIntensiveApp.classcd ..`
4. **Inicie os serviços com Docker Compose (se Docker Desktop ou Engine v2+):**`docker compose up --build`
Se estiver usando um Docker Engine mais antigo ou quiser simular o comportamento do Swarm (onde `deploy` é mais robusto), você pode inicializar o Swarm (se ainda não o fez: `docker swarm init`) e depois usar `docker stack deploy -c docker-compose.yml myapp`.
5. **Monitore o uso de CPU:**
Abra um novo terminal e execute:
`docker stats`

Você verá a saída de `docker stats` mostrando o uso de CPU para cada contêiner. O `backend-app` deverá ter seu uso de CPU limitado a aproximadamente 100% (se o sistema tiver mais de 1 núcleo) ou 0.5 de um núcleo se houver contenção forte e ele estiver usando apenas a reserva, enquanto o `monitoring-service` não excederá 25%.

**Observação para o Gedê:** Se você estiver fazendo a migração para Go, você faria um `main.go` que consuma CPU (similar ao Java `CpuIntensiveApp.java`) e então seu `backend/Dockerfile` seria algo como:

```
# Usa uma imagem Go para compilar
FROM golang:1.22-alpine AS builder
WORKDIR /app
COPY . .
RUN go mod init myapp && go mod tidy # Se usar módulos
RUN CGO_ENABLED=0 GOOS=linux go build -a -ldflags '-s -w' -o backend .

# Imagem final de runtime, mais leve
FROM alpine:latest
WORKDIR /app
COPY --from=builder /app/backend .
CMD ["./backend"]

```

---

### Sugestões para Aprofundamento

- **Entendimento de cgroups:** O Docker usa grupos de controle (cgroups) do Linux para gerenciar recursos. Aprofundar-se em como os cgroups funcionam pode dar uma visão mais profunda de como o Docker impõe esses limites.
- **Monitoramento Avançado:** Explore ferramentas de monitoramento de contêineres como Prometheus e Grafana, ou Datadog, que podem coletar métricas de CPU e exibir gráficos detalhados do uso ao longo do tempo. Isso é crucial para ajustar seus limites de forma inteligente.
- **Otimização de Aplicações:** Lembre-se que limitar a CPU é um remédio, não uma cura. A melhor prática é otimizar sua aplicação para que ela seja eficiente no uso de recursos. Profiling e otimização de código podem reduzir drasticamente a necessidade de altos limites de CPU.
- **Docker Swarm e Kubernetes:** Em orquestradores de contêineres maiores, como Docker Swarm ou Kubernetes, a gestão de recursos é ainda mais sofisticada, com agendadores que consideram esses limites e reservas para posicionar os contêineres nos nós corretos. Entender como eles funcionam pode ser o próximo passo na sua jornada.

---

Espero que essa explicação super detalhada tenha sido útil para você, Gedê\! Se tiver mais alguma dúvida ou quiser que A.R.I.A se aprofunde em outro tópico, é só chamar\!