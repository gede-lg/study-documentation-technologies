# cpu_shares

Claro, Gedê\! A.R.I.A está aqui para te ajudar a entender o `cpu_shares` do Docker Compose de forma bem detalhada, como você pediu. Vamos mergulhar nesse conceito que é tão importante para o gerenciamento de recursos em seus contêineres.

---

## Otimizando o Uso de CPU com `cpu_shares` no Docker Compose

### Introdução

No mundo da orquestração de contêineres com Docker e Docker Compose, a alocação eficiente de recursos é crucial para garantir o bom desempenho das aplicações. Um dos desafios comuns é evitar que um contêiner monopolize os recursos da CPU, prejudicando outros serviços rodando na mesma máquina. É aqui que o atributo `cpu_shares` entra em cena, oferecendo uma maneira de gerenciar a prioridade de acesso à CPU entre seus serviços. Ele não limita diretamente o uso da CPU a um valor absoluto, mas sim distribui a "fatia" do tempo de CPU disponível para cada contêiner em relação aos outros.

### Sumário

Nesta explicação detalhada, abordaremos os seguintes pontos:

- **Conceitos Fundamentais:** Entenderemos o que é `cpu_shares`, sua importância e propósito.
- **Sintaxe Detalhada e Uso Prático:** Veremos como configurar `cpu_shares` no seu arquivo `docker-compose.yml` com exemplos práticos.
- **Cenários de Restrição ou Não Aplicação:** Discutiremos quando `cpu_shares` pode não ser a melhor solução ou quando não tem efeito.
- **Componentes Chave Associados:** Abordaremos outros atributos relacionados ao gerenciamento de CPU.
- **Melhores Práticas e Padrões de Uso:** Dicas e recomendações para utilizar `cpu_shares` de forma eficaz.
- **Exemplo Prático Completo:** Um cenário com múltiplos serviços para ilustrar o uso.

---

### Conceitos Fundamentais

O atributo `cpu_shares` no Docker Compose (e no Docker em geral, via a flag `--cpu-shares` do comando `docker run`) é um parâmetro de alocação de CPU baseado em *peso* ou *proporção*. **Ele não define um limite máximo ou mínimo de CPU que um contêiner pode usar**, mas sim a proporção do tempo de CPU disponível que ele pode obter quando há **competição por recursos**.

Pense em `cpu_shares` como um sistema de pontos. Quando a CPU está ociosa, um contêiner pode utilizar 100% da CPU disponível, independentemente do seu `cpu_shares`. No entanto, quando múltiplos contêineres estão disputando o tempo da CPU, o Docker scheduler (agendador) distribuirá os ciclos de CPU proporcionalmente aos valores de `cpu_shares` configurados.

O valor padrão de `cpu_shares` para um contêiner é **1024**. Este é o valor "base" para a proporcionalidade. Se você tiver dois contêineres, um com `cpu_shares: 1024` e outro com `cpu_shares: 512`, o primeiro contêiner terá o dobro da prioridade de acesso à CPU em relação ao segundo, **quando ambos estiverem ativos e disputando recursos**. Matematicamente, o primeiro receberá $(1024 / (1024 + 512)) = 66.6%$ do tempo de CPU e o segundo $(512 / (1024 + 512)) = 33.3%$.

**Importância e Propósito:**

- **Evitar Monopolização:** Impede que um único serviço "faminto" por CPU sobrecarregue o sistema e impacte negativamente o desempenho de outros serviços essenciais.
- **Priorização de Serviços:** Permite que você defina quais serviços são mais críticos e devem ter maior acesso à CPU quando os recursos são limitados. Por exemplo, um serviço de banco de dados pode ter um `cpu_shares` maior que um serviço de log.
- **Otimização de Custos:** Em ambientes de nuvem, onde você paga por recursos computacionais, o `cpu_shares` pode ajudar a otimizar o uso da CPU em uma única instância, adiando a necessidade de escalar horizontalmente.
- **Previsibilidade:** Embora não seja um limite rígido, ele oferece uma forma de prever o comportamento dos contêineres sob carga pesada em relação uns aos outros.

---

### Sintaxe Detalhada e Uso Prático

O atributo `cpu_shares` é definido sob a chave `services` no arquivo `docker-compose.yml`.

**Sintaxe Básica:**

```yaml
version: '3.8' # Versão recomendada do Docker Compose
services:
  meu_servico_web:
    image: nginx:latest
    ports:
      - "80:80"
    cpu_shares: 512 # Define 512 cpu_shares para este serviço

  meu_servico_api:
    image: myapi:latest
    cpu_shares: 1024 # Define 1024 cpu_shares para este serviço

  meu_servico_batch:
    image: mybatch:latest
    cpu_shares: 2048 # Define 2048 cpu_shares para este serviço

```

**Explicação dos Valores:**

- Os valores de `cpu_shares` são inteiros positivos.
- O valor padrão é `1024`.
- Valores maiores indicam maior prioridade/peso.
- Valores menores indicam menor prioridade/peso.

**Exemplos Comentados:**

Vamos considerar um cenário onde você tem três serviços:

1. **`frontend`**: Um servidor web que serve páginas estáticas, geralmente não muito intensivo em CPU.
2. **`backend`**: Uma API que processa requisições, podendo ser moderadamente intensiva em CPU.
3. **`processador_dados`**: Um serviço que executa tarefas pesadas de processamento de dados em segundo plano, que pode ser muito intensivo em CPU.

<!-- end list -->

```yaml
version: '3.8'
services:
  frontend:
    image: nginx:alpine
    ports:
      - "80:80"
    # Este serviço tem menor prioridade de CPU, pois geralmente é mais leve.
    # Se houver escassez de CPU, outros serviços terão preferência.
    cpu_shares: 256

  backend:
    image: my-backend-image
    environment:
      - PORT=8080
    ports:
      - "8080:8080"
    # Este serviço tem prioridade padrão, adequado para a maioria das APIs.
    # Pode usar mais CPU se disponível, mas cederá para serviços de maior prioridade.
    cpu_shares: 1024 # Equivalente ao padrão, mas explicitamente definido para clareza

  processador_dados:
    image: my-data-processor-image
    # Este serviço é crítico e intensivo em CPU, merece a maior fatia.
    # Ele terá o dobro da prioridade do backend e muito mais do frontend quando a CPU estiver sob demanda.
    cpu_shares: 2048

  # Exemplo de serviço com cpu_shares muito baixo, para tarefas de baixa prioridade
  log_analyser:
    image: log-analyser:latest
    cpu_shares: 128
    # Este serviço só rodará quando a CPU estiver relativamente livre ou
    # usará uma parcela muito pequena em caso de contenção.

```

Neste exemplo:

- Se `frontend`, `backend` e `processador_dados` estiverem todos disputando a CPU, `processador_dados` terá a maior fatia, seguido por `backend` e depois `frontend`.
- A proporção seria: `frontend` (256) : `backend` (1024) : `processador_dados` (2048).
- A soma total dos shares é `256 + 1024 + 2048 = 3328`.
- `frontend` obteria aproximadamente $(256 / 3328) \\approx 7.7%$ do tempo de CPU.
- `backend` obteria aproximadamente $(1024 / 3328) \\approx 30.7%$ do tempo de CPU.
- `processador_dados` obteria aproximadamente $(2048 / 3328) \\approx 61.5%$ do tempo de CPU.

**Lembre-se: Essas porcentagens são válidas *apenas quando há contenção de CPU*. Se apenas um contêiner estiver ativo e demandando CPU, ele poderá usar 100% dos recursos disponíveis na máquina host.**

---

### Cenários de Restrição ou Não Aplicação

Embora `cpu_shares` seja uma ferramenta útil, há situações em que ela pode não ser a melhor escolha ou onde seu efeito é limitado:

- **CPU Ociosa:** Se o seu host Docker tiver muita CPU disponível e os contêineres raramente disputarem recursos, o `cpu_shares` terá pouco ou nenhum efeito prático. Todos os contêineres poderão usar a CPU conforme necessário.
- **Limites Absolutos:** `cpu_shares` **NÃO é um limite absoluto de CPU**. Se você precisa garantir que um contêiner nunca exceda uma certa porcentagem ou um número fixo de cores da CPU (por exemplo, "nunca mais que 50% de um core" ou "nunca mais que 2 cores"), você precisará usar outros atributos como `cpus` (para um número fixo de cores) ou `cpu_percent`, `cpu_period` e `cpu_quota` (para limites baseados em porcentagem/tempo).
- **Máquinas com Poucos Cores:** Em sistemas com um único core de CPU, a granularidade do `cpu_shares` pode ser menos perceptível, mas ainda assim influenciará a alternância de tempo entre os processos.
- **Cargas de Trabalho Irregulares:** Para cargas de trabalho que têm picos de uso de CPU muito curtos e esporádicos, o `cpu_shares` pode não ser a forma mais eficaz de gerenciamento. Outras estratégias de escalonamento ou balanceamento de carga podem ser mais apropriadas.
- **Integração com Orquestradores:** Em orquestradores de contêineres como Kubernetes, a forma de gerenciar e alocar CPU é feita através de `requests` e `limits` para CPU, que oferecem um controle mais granular e com garantias de QoS (Quality of Service) que `cpu_shares` por si só não provê. O `cpu_shares` é um conceito mais fundamental do cgroups do Linux que o Docker abstrai, e outros orquestradores constroem em cima disso.

---

### Componentes Chave Associados

O Docker Compose oferece outros atributos que trabalham em conjunto com (ou como alternativas a) `cpu_shares` para um controle mais refinado da CPU. Eles são tipicamente usados dentro da mesma seção `resources` dos serviços.

Vamos analisar alguns dos mais importantes:

1. **`cpus`**:
    - **Descrição:** Define um limite rígido de quantas CPUs (ou frações de CPU) um contêiner pode usar. É um limite absoluto.
    - **Uso:** `cpus: 0.5` significa que o contêiner pode usar no máximo meio core de CPU. `cpus: 2` significa que ele pode usar no máximo 2 cores completos.
    - **Sintaxe:**
        
        ```yaml
        services:
          meu_servico:
            image: minha-imagem
            deploy:
              resources:
                limits:
                  cpus: '0.5' # Limita o serviço a usar no máximo meio core
                reservations:
                  cpus: '0.25' # Reserva um quarto de core para o serviço (usado mais em Swarm/Kubernetes)
        
        ```
        
    - **Diferença para `cpu_shares`:** `cpus` é um **limite máximo**, enquanto `cpu_shares` é um **peso/prioridade** quando há contenção. Um contêiner com `cpus: 0.5` nunca excederá o uso de meio core, mesmo que o sistema esteja ocioso.
    - **Importante:** No Docker Compose, `cpus` faz parte da chave `deploy.resources.limits.cpus`.
2. **`cpu_period` e `cpu_quota`**:
    - **Descrição:** Estes dois atributos trabalham juntos para definir um limite de CPU por um período de tempo. `cpu_period` é o período de tempo (em microssegundos, padrão 100000ms), e `cpu_quota` é a quantidade de tempo (em microssegundos) que o contêiner pode usar a CPU dentro desse período.
    - **Uso:** Para limitar um contêiner a 50% de um core, você configuraria `cpu_period: 100000` e `cpu_quota: 50000`. Isso significa que, a cada 100ms, o contêiner pode usar a CPU por no máximo 50ms.
    - **Sintaxe:**
        
        ```yaml
        services:
          meu_servico:
            image: minha-imagem
            cpu_period: 100000 # Padrão: 100ms
            cpu_quota: 50000 # 50% de um core
        
        ```
        
    - **Diferença para `cpu_shares`:** Similar ao `cpus`, `cpu_quota` + `cpu_period` impõem um **limite rígido**. Um contêiner nunca excederá a porcentagem definida, mesmo se houver CPU disponível. `cpu_shares` permite que o contêiner "estoure" sua proporção se outros contêineres não estiverem usando a CPU.
    - **Aplicações:** Útil para garantir que um contêiner de baixa prioridade não sobrecarregue o sistema, mesmo que os outros serviços estejam ociosos.
3. **`cpuset`**:
    - **Descrição:** Permite que você "fixe" um contêiner a um conjunto específico de CPUs físicas no host.
    - **Uso:** `cpuset: "0,1"` aloca o contêiner apenas para usar os cores 0 e 1. `cpuset: "0-3"` aloca para os cores 0, 1, 2 e 3.
    - **Sintaxe:**
        
        ```yaml
        services:
          servico_critico:
            image: critical-app:latest
            cpuset: "0" # Fixa o serviço ao primeiro core de CPU
        
        ```
        
    - **Aplicações:** Geralmente usado em cenários de alta performance ou isolamento, onde você quer garantir que um serviço muito sensível ao latência rode em cores dedicados e evite a alternância de contexto (context switching) com outros processos.
    - **Considerações:** Pode levar a um uso ineficiente da CPU se os cores alocados estiverem ociosos e outros contêineres precisarem de CPU. Deve ser usado com cautela.

**Interação entre os Atributos:**

- **`cpu_shares` vs. `cpus`/`cpu_quota`:** Se você usar `cpu_shares` e `cpus` (ou `cpu_quota`), o `cpus`/`cpu_quota` será o limite predominante. O `cpu_shares` só entrará em jogo para a proporcionalidade *dentro* do limite definido por `cpus`/`cpu_quota`. Por exemplo, se você tem 2 contêineres, ambos com `cpus: 0.5`, mas um com `cpu_shares: 2048` e outro com `cpu_shares: 1024`, e ambos estão usando o máximo de sua CPU dentro do limite de 0.5 core, o `cpu_shares` não terá efeito direto no *limite*, mas sim na prioridade *se houver contenção no próprio limite*. Na prática, o `cpus` ou `cpu_quota` são mais diretos para limitar o uso total.
- **`cpuset` e Outros:** Quando `cpuset` é usado, os outros limites de CPU (como `cpu_shares` ou `cpus`) aplicam-se *apenas aos cores especificados pelo `cpuset`*. Ou seja, o contêiner não pode usar CPU fora do conjunto definido, e quaisquer limites de CPU serão impostos sobre os recursos *dentro* desse conjunto.

---

### Melhores Práticas e Padrões de Uso

Para Gedê, que é desenvolvedor Backend Java e busca Go, o gerenciamento de recursos é fundamental para aplicações de alta performance.

1. **Entenda sua Carga de Trabalho:**
    - Antes de configurar `cpu_shares`, monitore seus contêineres para entender seus padrões de uso de CPU. Quais serviços são intensivos em CPU? Quais são mais leves?
    - Ferramentas como `docker stats` ou soluções de monitoramento (Prometheus, Grafana) são essenciais.
2. **Comece com o Padrão:**
    - Para a maioria dos serviços, o `cpu_shares` padrão de `1024` é um bom ponto de partida. Ajuste apenas quando houver problemas de contenção de CPU ou necessidade de priorização.
3. **Use `cpu_shares` para Priorização Relativa:**
    - Se você tem serviços de diferentes criticidades ou com requisitos de desempenho variados, use `cpu_shares` para dar mais peso aos mais importantes.
    - **Exemplo:**
        - Serviço de Processamento Crítico: `cpu_shares: 2048` (alta prioridade)
        - API de Requisições: `cpu_shares: 1024` (prioridade padrão)
        - Serviço de Cache/Auxiliar: `cpu_shares: 512` (baixa prioridade)
4. **Combine com Limites Rígidos (quando necessário):**
    - Se um serviço, mesmo com `cpu_shares` baixo, ainda está causando problemas ao usar 100% da CPU quando outros serviços estão ociosos, considere adicionar um limite rígido com `cpus` ou `cpu_quota`. Isso garante que ele nunca excederá um certo patamar.
    - **Exemplo:**
    Neste caso, mesmo que o sistema esteja livre, `background_job` nunca usará mais de 25% de um core. Quando houver contenção, ele terá prioridade baixa entre os contêineres dentro de seus respectivos limites.
        
        ```yaml
        services:
          background_job:
            image: job-runner:latest
            cpu_shares: 512 # Baixa prioridade
            deploy:
              resources:
                limits:
                  cpus: '0.25' # Limite rígido de 25% de um core
        
        ```
        
5. **Evite Valores Extremos (sem necessidade):**
    - Valores muito baixos (ex: `cpu_shares: 1`) podem levar a um desempenho muito pobre para o contêiner, tornando-o quase inútil em cenários de alta carga. Valores muito altos podem ser enganosos, já que a proporção é relativa a *outros* contêineres.
6. **Teste em Cargas Reais:**
    - A única maneira de saber se suas configurações de `cpu_shares` são eficazes é testá-las sob carga simulada ou real. Monitore o uso de CPU, latência das requisições e throughput dos seus serviços.
7. **Documente suas Escolhas:**
    - Especialmente em equipes, documente por que certos valores de `cpu_shares` ou outros limites de CPU foram escolhidos para cada serviço. Isso ajuda a manter a consistência e o entendimento.

---

### Exemplo Prático Completo

Vamos criar um cenário com um projeto simplificado para ilustrar o uso de `cpu_shares` para Gedê, pensando em uma aplicação backend típica.

Considere uma aplicação com os seguintes serviços:

- **`web`**: Um servidor Nginx que serve a interface web. Geralmente de baixa demanda de CPU, mas precisa responder rapidamente.
- **`api`**: Sua aplicação Go (ou Java, já que você é desenvolvedor Java\!) de backend, que lida com a lógica de negócios e persistência. Este serviço pode ter picos de CPU.
- **`worker`**: Um serviço de processamento em segundo plano (ex: fila de mensagens, processamento de imagens). Este pode ser intensivo em CPU e pode ser adiado em caso de escassez de recursos.
- **`database`**: Um banco de dados (PostgreSQL neste caso). Embora os bancos de dados sejam intensivos em I/O, eles também usam CPU para consultas e gerenciamento, e garantir alguma prioridade pode ser benéfico.

<!-- end list -->

```yaml
version: '3.8'

services:
  web:
    image: nginx:latest
    container_name: web-server
    ports:
      - "80:80"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf:ro
      - ./html:/usr/share/nginx/html:ro
    # Prioridade de CPU relativamente baixa, pois serve conteúdo estático.
    # Pode ceder CPU para a API e o banco de dados em caso de contenção.
    cpu_shares: 512
    healthcheck:
      test: ["CMD", "curl", "-f", "<http://localhost>"]
      interval: 30s
      timeout: 10s
      retries: 3

  api:
    build: ./backend-api # Supondo que você tenha uma pasta 'backend-api' com seu Dockerfile para Go/Java
    container_name: api-service
    ports:
      - "8080:8080"
    environment:
      DATABASE_URL: "postgresql://user:password@database:5432/mydatabase"
    depends_on:
      database:
        condition: service_healthy
    # Prioridade padrão para a API, pois é o coração da aplicação.
    # Precisa de uma fatia justa da CPU para responder às requisições.
    cpu_shares: 1024
    healthcheck:
      test: ["CMD", "curl", "-f", "<http://localhost:8080/health>"]
      interval: 30s
      timeout: 10s
      retries: 3

  worker:
    build: ./background-worker # Supondo uma pasta 'background-worker'
    container_name: worker-service
    environment:
      QUEUE_URL: "rabbitmq://..."
    depends_on:
      api:
        condition: service_healthy # O worker pode depender da API ou do banco
    # Este é um serviço de processamento em segundo plano que pode ser pesado.
    # Ele recebe uma prioridade maior, pois os jobs precisam ser processados.
    # No entanto, se o sistema estiver sob extrema carga, ele não deve derrubar a API.
    # Aqui, a escolha de 1536 é um meio termo, maior que a API mas não o dobro.
    cpu_shares: 1536
    healthcheck:
      test: ["CMD", "echo", "Worker is alive"] # Exemplo simples, ajustar para sua lógica
      interval: 1m
      timeout: 10s
      retries: 2

  database:
    image: postgres:13
    container_name: my-database
    environment:
      POSTGRES_DB: mydatabase
      POSTGRES_USER: user
      POSTGRES_PASSWORD: password
    volumes:
      - db_data:/var/lib/postgresql/data
    # O banco de dados é um componente crucial. Garantimos uma prioridade alta para ele.
    # Isso ajuda a garantir que as operações de leitura/escrita não sejam excessivamente impactadas
    # pela contenção de CPU de outros serviços menos críticos.
    cpu_shares: 2048
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U user -d mydatabase"]
      interval: 5s
      timeout: 3s
      retries: 5

volumes:
  db_data:

```

**Diretórios e Arquivos Auxiliares (apenas para o exemplo):**

- `nginx.conf`:
    
    ```
    events {
        worker_connections 1024;
    }
    http {
        server {
            listen 80;
            location / {
                root /usr/share/nginx/html;
                index index.html;
            }
            location /api/ {
                proxy_pass <http://api-service:8080/>; # Nginx encaminhando para a API
            }
        }
    }
    
    ```
    
- `html/index.html`:
    
    ```html
    <!DOCTYPE html>
    <html>
    <head>
        <title>Minha Aplicação</title>
    </head>
    <body>
        <h1>Bem-vindo à Minha Aplicação Docker!</h1>
        <p>A API está acessível em /api/</p>
    </body>
    </html>
    
    ```
    
- `backend-api/Dockerfile`: (Exemplo simples para Go)
    
    ```
    FROM golang:1.22-alpine
    WORKDIR /app
    COPY . .
    RUN go mod download
    RUN go build -o main .
    EXPOSE 8080
    CMD ["./main"]
    
    ```
    
- `background-worker/Dockerfile`: (Exemplo simples para Python, adaptável para Go)
    
    ```
    FROM python:3.9-alpine
    WORKDIR /app
    COPY . .
    RUN pip install -r requirements.txt # Se tiver dependências
    CMD ["python", "worker.py"]
    
    ```
    

**Como este exemplo funcionaria sob carga:**

Se a máquina host estiver com alta demanda de CPU e todos os serviços estiverem ativos:

- O `database` terá a maior fatia de CPU devido ao seu `cpu_shares: 2048`.
- O `worker` virá em seguida com `cpu_shares: 1536`.
- A `api` manterá uma fatia padrão (`cpu_shares: 1024`).
- O `web` terá a menor prioridade (`cpu_shares: 512`), cedendo CPU aos outros se necessário.

Isso ajuda a garantir que os serviços mais críticos e intensivos (banco de dados, worker, API) recebam tempo de CPU preferencial quando os recursos são escassos, mantendo a responsividade geral da aplicação.

---

Espero que esta explicação detalhada sobre o `cpu_shares` no Docker Compose seja útil para você, Gedê\! Se tiver mais alguma dúvida, é só perguntar.